# Préface

> « [Algorithme]. Ce terme d’informatique a une signification bien plus large qu’on ne le croit. Comme la recette de cuisine, un algorithme est une série d’instructions permettant d’obtenir un résultat. À très grande vitesse, il opère un ensemble de calculs à partir de gigantesques masses de données [...] Il hiérarchise l’information, devine ce qui nous intéresse, sélectionne les biens que nous préférons et s’efforce de nous suppléer dans de nombreuses tâches.  
> Nous fabriquons ces calculateurs, mais en retour ils nous construisent. Il n’est plus beaucoup de gestes quotidiens, d’achats, de déplacements, de décisions personnelles ou professionnelles qui ne soient orientés par une infrastructure de calculs. Quand elle vient soudainement à disparaître, comme lorsqu’une panne interrompt le trafic téléphonique, nous sommes désemparés. Pourtant, dès que nous pensons à la présence des calculateurs dans nos sociétés, nous maudissons la froide rationalité des machines et redoutons qu’elles ne prennent le pouvoir sur nous. Nous aimons leur opposer « notre » subtile sagacité. »  
— D. Cardon, « *À quoi rêvent les algorithmes* »

Smartphones, réfrigérateurs « intelligents », télévisions « connectées », pèse-personnes... l’algorithme appareille aujourd’hui nos dispositifs personnels, orientant nos décisions. Inséré dans les systèmes de régence sociétales que sont la Bourse ou Internet, produisant des rapports d’études et des analyses socio-économiques, il justifie jusqu’à des choix politiques.
Cardon pose ainsi le paradoxe fondamental de la place de l’algorithme dans nos sociétés. Omniprésent, il garde sa part de mystère (//exergue). Nous avons beau prendre conscience de son importance et peu à peu parler d’une « culture algorithmique » (//nbp : internetactu.net), nous interrogeons ses effets sans suffisamment examiner sa fabrication ou son fonctionnement.

Il convient alors d’aborder le titre de ce mémoire, et les enjeux que soulèvent son rapport à l’algorithme.
Une boîte noire, c’est une façon de représenter un système sans considérer son fonctionnement (//schéma corps de texte : boîte noire). Nous devons le terme au mathématicien Norbert Weiner (//nbp bio), qui théorise le concept en 1948 dans *Cybernétique et société*.
La notion de boîte noire naît durant la Seconde Guerre mondiale du besoin d’étudier des dispositifs de cryptages militaires ennemis sans avoir besoin de comprendre leur fonctionnement interne. Ainsi, en étudiant les messages chiffrés d’Enigma (//nbp explication : ) l’informaticien britannique Alan Turing réussira à déduire le fonctionnement de la machine, ce qui permettra de décrypter les communications de l’Axe, offrant en définitive la victoire aux Alliés.
Aujourd’hui, le concept de boîte noire permet aux théoriciens des systèmes, aux économistes et sociologues d’assumer l’analyse et l’impact de systèmes complexes sans avoir pour autant besoin de connaître ou de décrire leur fonctionnement.

(//insérer le tweet drôle)

Il n’y a pour l’instant pas encore de réelle « culture algorithmique ». Il y a, par contre, une véritable « culture de la boîte noire ». Et encastrer l’algorithme dans une boîte noire ne permet ni de comprendre sa place dans nos sociétés, ni de définir le rapport que nous entretenons avec.
Comme l’explique Cardon au sujet de son livre (//nbp interview France inter), nous avons aujourd’hui une attitude de repli en se disant qu’après tout, puisque nous sommes incapables de comprendre ces boîtes noires, de les *ouvrir*, autant finalement les laisser faire pour nous, en espérant qu’elles fassent au mieux. Beaucoup d’idées reçues découlent de cette attitude et questionnent notre rapport à la froide précision de l’algorithme, sans pour autant réussir à révéler ses enjeux fondamentaux.
Il semble alors crucial de réussir à ouvrir ces boîtes noires afin de mieux comprendre les algorithmes qui y résident, et ainsi relever les enjeux et problématiques qui les animent.

//saut de page ou colonne, rupture distincte

Si ce mémoire se propose d’ouvrir ces boîtes noires, il est surtout l’occasion pour moi de cristalliser des observations nées d’une dizaine d’années de pratique algorithmique, de partager mes questionnements et mon rapport personnel à l’algorithme, mais aussi de relever des problématiques qui, je l’espère, influeront ma démarche pour les années à venir.

Le sensible, c’est la confusion, disait Descartes. Je me suis développé autour de cette idée que notre monde, nos relations, toute la complexité de la vie, du réel, de l’humanité, pouvait être algorithmisée, et que ce faisant tout deviendrait plus simple. Une pratique personnelle de la programmation et de l’algorithme me pousse pourtant aujourd’hui à vouloir concevoir des systèmes sensibles et intuitifs, capables de faire sens sur un plan esthétique (//nbp : ethymologie « perçu par les sens »), qui intéresse la sensibilité et la touche. L’algorithme tel que je le conçois est aujourd’hui un algorithme compagnon d’une démarche de création, et je souhaite ici en partager ma vision sensible.
Mais n’est-ce pas contradictoire d’envisager l’algorithme dans un rapport sensible, le considérant comme un outil esthétique et non plus uniquement au service de la rigueur technique ? Dans ce cas, comment le définir en tant que tel, et comment placer notre propre Humanité en regard d’un objet témoignant d’une intelligence sensible ? 

Pour donner corps à cette problématique, je propose alors de diviser le discours en une dizaine de parties. Parce que l’algorithme est par essence systémique, il devient intéressant de l’étudier au travers de ses multiples facettes, et d’aborder séparément les questions clefs qui le construisent, et les paradoxes qui l’animent. Par touches impressionnistes, j’espère alors réussir à dresser son portrait afin d’en donner une vision holistique, et ainsi amener vers la notion *culture algorithmique*.

Citation en exergue : 
> « La vocation du livre est pédagogique, c’est-à-dire qu’il ne faut pas voir le numérique comme un tout, mais le décomposer pour voir comment ses différentes parties interagissent avec nos vies. Décomposer les variables autour desquelles la « salade algorithmique » se compose. Il y a un enjeu là-dessus qui est effectivement important : pour bien critiquer, il faut être capable d’entrer dans ces systèmes pour les comprendre. Cela ne signifie pas qu’il faut savoir coder en Python, ou être statisticien expert ; mais entre les deux, il y a une zone de langage et d’exploration critique dans laquelle il faut s’aventurer réellement. Être en position de réflexion face à ces usages, et être capable de les décoder. On imagine toujours une sorte de docilité passive de l’utilisateur, toujours mené par le haut au travers des prescriptions qui lui sont faites. » — Cardon, France culture, 17’00’’


