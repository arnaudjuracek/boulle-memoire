#Erreur (à placer avant émergence)

L’algorithme est un objet qui permet d’arriver à un résultat. Ce résultat est soit la réponse à un problème (Euclide : quelle est le plus grand commun diviseur entre ces deux nombres ?), soit le produit d’une série de manipulation (une recette de cuisine par exemple). Fondamentalement, il est donc un objet qui résout.
Si ce résultat n’est pas forcément consistant ou prédictible, on n’en attend pas moins que l’algorithme *fonctionne*, c’est-à-dire qu’il produise le résultat pour lequel il a été conçu. Dans le cas contraire, l’algorithme est inexploitable, *cassé*.
L’erreur n’est donc pas souhaitable dans une pratique algorithmique classique.

Parce que les algorithmes modernes sont de plus en plus complexes et qu’ils impliquent souvent un nombres très importants de sous-algorithmes inter-dépendants, il peut cependant parfois être difficile d’assurer un programme parfaitement fiable. Si l’industrie du logiciel alloue des budgets conséquents au *débugging* et développe des tests méthodiques de vérifications des algorithmes, il est parfois plus simple —et souvent moins cher— de compter sur un seuil d’erreur admissible. Les algorithmes d’optimisation de trajets (ou *pathfinding*) par exemple choisissent de déplacer le curseur vers une réponse probable en un temps minimum d’exécution, plutôt que  d’arriver à un résultat parfait en un temps souvent bien plus long. Cette optimisation est la clef de voute de l’algorithmique moderne //HFT

Il est pourtant communément accepté qu’un algorithme —et par amalgame une machine— ne doive pas faire d’erreur. Une recherche récemment menée à l’université de Pennsylvanie (http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2466040) démontre à ce propos que les gens sont réticents à donner une seconde chance à un algorithme qui semble s’être trompé, même s’ils acceptent le fait qu’il soit à priori plus fiable qu’un humain.
> « Bien sûr, aucun algorithme n’est parfait, soulignent les chercheurs, mais nous sommes plus enclins à leur reprocher leur imperfections qu’aux humains. En fait, quand une machine fait une erreur, nous avons tendance à penser qu’elle pourra la refaire - ce qui est certainement de moins en moins vrai à l’heure des machines apprenantes. » —http://alireailleurs.tumblr.com/post/111360073624/laversion-aux-algorithmes-knowledge-wharton

Dans son essai *Computing Machinery and Intelligence*, Alan Turing attaque le mythe de la machine parfaite, en distinguant notamment deux types d’erreurs : 
> « The claim that "machines cannot make mistakes" seems a curious one. [...] It seems to me that this criticism depends on a confusion between two kinds of mistake, we may call them "**errors of functioning**" and "**errors of conclusion**".
> [...] In philosophical discussions one likes to ignore the possibility of such errors; one is therefore discussing "abstract machines." These abstract machines are mathematical fictions rather than physical objects. By definition they are incapable of errors of functioning. In this sense we can truly say that "machines can never make mistakes." Errors of conclusion can only arise when some meaning is attached to the output signals from the machine. »

Selon lui, l’erreur algorithmique (la machine de Turing est une machine algorithmique) peut donc être de deux types : de fonctionnement et de conclusion.

L’erreur de fonctionnement est physique : la machine est littéralement cassée, un élément constitutif ne fonctionne pas, entraînant un comportement global erratique. En 1946, alors que Hopper travaille sur l’ordinateur électro-mécanique Mark II d’Harvard, il découvre une erreur causée par une mite coincée dans un relai de la machine. Cette erreur causée par un insecte donne naissance au terme *bug*, qui dès lors décrira un problème de fonctionnement dans une machine, et par abus de langage une erreur informatique, quelle que soit sa typologie.
Comme le souligne Turing, l’erreur de fonctionnement ne peut donc exister si l’on s’intéresse uniquement à l’algorithme comme une abstraction mathématique. Dans un monde parfait, l’incarnation matérielle d’un algorithme (que ce soit au travers du métier à tisser Jacquard ou au sein d’un microprocesseur) ne devrait pas entraîner d’erreur de fonctionnement.

Par opposition l’erreur de conclusion est méta-physique, et ne peut être évacuée en abstraisant l’algorithme. Un bon exemple d’une telle erreur peut être trouvé dans le *Cycle des Robots* d’Isaac Asimov. Dans l’une des nouvelles du recueil Powell et Donovan, deux roboticiens, sont appelés pour réparer un robot *bugué*. Ce robot, chargé de transporter d’un point A à un point B un objet dans l’hostile environnement martien, est occupé depuis plusieurs jours à tourner autour d’un cratère, faillant à sa mission. En étudiant l’algorithme définissant le comportement dudit robot, les deux roboticiens comprennent rapidement que l’erreur est une erreur logique, et non mécanique : si le robot à effectivement pour tâche de se déplacer d’un point A à un point B, la résolution de l’itinéraire qu’il emprunte doit cependant respecter les lois de la robotique, et notamment la consigne de ne pas se mettre en danger. En s’approchant du cratère, le robot c’est ainsi retrouvé face à un problème insoluble : réussir à traverser le cratère pour rejoindre sa destination sans pour autant se mettre en danger. (//mal expliqué, à compléter avec le livre prêté à Maïté).
Du point de vue du robot, il n’y a pas d’erreur : l’exécution de l’algorithme est correcte, les consignes données sont suivies à la perfection. « Errors of conclusion can only arise when some meaning is attached to the output signals from the machine », précise Turing : l’erreur n’est erreur que dans le contexte plus général de la tâche attribuée au robot. Du point de vue de l’algorithme, l’erreur de conclusion n’existe pas : il n’y a que la froide exécution qui compte.

L’erreur est humaine, dit-on. Et en ce sens l’algorithme donne raison à cet adage. //bof md
« It is claimed that the interrogator could distinguish the machine from the man simply by setting them a number of problems in arithmetic. The machine would be unmasked because of its deadly accuracy. » — Turing
Machine capable de simuler des erreurs deviendrait plus humaine.

Est-il alors possible de concevoir un algorithme capable de donner sens à l’erreur, d’être capable de la prendre en compte ? On considère aujourd’hui cette question comme l’une des principales limites à l’automatisation, et de nombreuses recherches sont menées en ce sens. Turing encore une fois offre dès 1950 les bases réflexives à cette problématique, en imaginant une machine « apprenante », capable de déceler une erreur de conclusion et d’adapter son fonctionnement en conséquence. Le site web Akinator est un exemple très trivial d’une telle machine. //décrire le site et le fonctionnement de l’algo : plus il fait d’erreurs, moins il fait d’erreurs.

//GLITCH ART : donner du sens à une erreur qui n’en a pas. définir une esthétique de l’erreur, mais aussi donner à voir le fonctionnement