#02 — input/output et mapping

Fondamentalement, l’algorithme est avant tout un objet qui permet de transformer une entrée (*input* en anglais) en sortie (*output*). Son intérêt premier est donc de produire un résultat. Ce résultat est la transformation d’une entrée par le biais d’une série d’instructions. 
En vertu du principe de la boîte noire, il est possible d’étudier l’algorithme en éludant son fonctionnement interne et en s’intéressant exclusivement à son couple *input/output*. Dans le cadre des problématiques posées en introduction, il semble alors important de réussir à définir les enjeux de ce couple avant même d’étudier le fonctionnement de l’algorithme.

Parce que l’algorithme possède autant de formes qu’il a d’applications, il est difficile de tenir un propos général le concernant. Pire encore : il n’est pas exclu qu’un algorithme fasse intervenir plusieurs entrées simultanément (si l’on considère une recette de cuisine comme un algorithme, alors les ingrédients nécessaires à la production du repas sont les *inputs*), ou même plusieurs sorties.
C’est pourquoi je propose d’étudier la notion fondamentale d’*input/output* au travers d’un exemple permettant de clarifier le discours : les vases#44 de François Brument. En proposant une série de vases générés par le son de la voix, Brument offre un exemple trivial d’algorithme à vocation esthétique, et permet d’étudier un couple *input/output* intéressant.
(//images vases, principe de fonctionnement)
L’entrée est ici explicite : il s’agit du son capté par l’ordinateur embarquant l’algorithme de génération de vase. La sortie, c’est bien évidemment le vase lui même, ou plutôt sa modélisation en trois dimensions, qui servira ensuite de support à l’impression du vase final. (//schéma son>algo>3D). Qu’est-ce que l’algorithme met alors en jeu pour être seulement capable d’appréhender la complexité et la sensibilité d’une voix ?

L’algorithme restant avant tout outil de désambiguïsation, et son champ d’application aujourd’hui étant principalement numérique, il convient tout d’abord d’établir des formats de données interprétables par un ordinateur. Ainsi, avant même l’élaboration de l’algorithme, le travail de conception algorithmique est avant tout un travail de traduction. C’est ici qu’intervient la notion très importante de *datatype* (« type de donnée » en Français).
Il existe, selon les applications et les supports utilisés pour la création d’un algorithme, un certain nombre de *datatypes* qu’une machine sera capable d’appréhender et de manipuler. Parce qu’un ordinateur —et par extension un algorithme— utilise un langage mathématique, ces *datatypes* seront dans l’absolu toujours numériques. Ce n’est alors que par une méthodique numérisation de chaque entrée que l’algorithme peut fonctionner.
(// un petit exergue sur une autre page avec quelques exemples de dataptypes : caractère, entiers, virgule... et leur combinaison (string, array))
Dans le cas de Vases#44 par exemple, ce que nous percevons comme une voix, un cri, un sifflement ou un applaudissement ne sera pour l’algorithme qu’une série de chiffres traduisant dans le temps un changement de fréquence sonore (//image d’une onde sonore et équivalent numérique).
L’enjeu premier de la conception algorithmique, c’est alors de réussir à décomposer un phénomène qui nous apparaît complexe et sensible (un son, un mouvement, une image...) en un objet mathématique manipulable par une machine. Si cela semble trivial dans le cas d’algorithmes manipulant par défaut des objets numériques (typiquement des algorithmes mathématiques), cela pose un réel problème dans le cas d’algorithmes utilisés dans des applications plus sensibles : la traduction de phénomènes en langage mathématique n’amputerait-elle pas une part de leur sensibilité ? 
C’est l’une des questions qu’adresse le projet *Data Masks* de Sterling Crispin (//nbp : ref), en proposant d’utiliser les données de reconnaissances faciales collectées par Facebook pour produire des impressions 3D de ce que la machine considère comme un visage. Pour fonctionner efficacement, les algorithmes de « *computer vision* » (//nbp : souvent abrégé CV, terme désignant le domaine de recherche d’algorithmes capables de comprendre, de « lire » une image, // faire ref au projet de CV de la Stanford University) mettent en place des des relevés géométriques identitaires d’un visage : en exploitant ses relevés pour produire ses *Data Masks*, Crispins nous propose de voir ce que voit l’algorithme, des sortes de « fantômes dérangeants » selon lui. « The kind of softness, the part that’s really human, is lost in all of this [process] » (//nbp ref à l’article medium, citation de Crispin). Pour l’artiste, la sensibilité est perdue dans cette algorithmisation de nos visages : est-il alors vain de convoquer une pratique algorithmique dans le cadre d’une production esthétique ?

(//citation en exergue bien flottant : « la nature est un livre écrit en langage mathématique » — Galilée)

Introduire la notion de *datatype*, correspond à introduire une propriété émergente de l’utilisation de l’algorithme : le *mapping*.
De l’Anglais *map* (carte en Français), le *mapping* (parfois également appelé « *data-mapping* ») désigne une pratique mathématique de transposition de données d’un *datatype* à un autre (on peut aussi parler de *morphisme*). Lorsque François Brument propose de générer des vases à partir d’un son, il choisit d’interpréter une onde sonore en terme de formes en trois dimensions, pratiquant alors le *mapping* d’un son en un espace 3D.
Cette pratique du *mapping* se retrouve aujourd’hui dans de nombreux domaines, et témoigne d’une volonté d’algorithmisation de notre monde. Parfois, comme dans le cas des visualisations de données, il s’agit de donner à voir sous une autre forme un jeu de données afin de lui donner du sens, en le transposant par exemple vers un média plus facile à appréhender. (//ex visuel d’une dataviz de CatalogTree). D’autres fois, cette transposition permet d’insuffler une sensibilité nouvelle à un phénomène, en le convoquant dans un environnement d’expression où l’on ne l’attendrait pas. 
C’est le cas par exemple de l’« Atlas Eclipticalis » (1961/62) et des « Études Australes » (1974-75) de John Cage (//nbp : 1961-62 — https://vimeo.com/49288980, //ref : Malaysian Music Journal Vol. 2, Num. 2 (74-89) - John Cage’s Atlas Eclipticalis: Paving the Way to Anthropocentric Processual Creation — http://mmj.upsi.edu.my/images/P5-8-MMJ-TZU-ENG_NGIAO.pdf), des compositions pour orchestre et piano écrites à partir de cartes astronomiques. En posant des bandes de papier calque sur des cartes astrales et en y reportant la position des étoiles, Cage développe une méthode lui permettant de composer une musique nouvelle, libérée des contraintes de structures et d’intention. « [this method] permitted the writing of a music which was not based on harmony, but it permitted harmonies to enter into such a nonharmonic music » (//nbp : Kostelanetz, Richard. 2003. Conversing with John Cage. New York: Routledge., p91). En choisissant de *mapper* la position des étoiles en un système de notation musicale, Cage offre ainsi à ses compositions une sensibilité nouvelle née d’une pratique transversale. Il influe alors à sa musique l’harmonie du ballet des étoiles, jusqu’alors inaudible.

Ainsi, l’algorithmisation d’un objet (qu’il soit un phénomène sensible, une donnée physique ou numérique) nécessite de pouvoir traduire cet objet dans un langage que l’algorithme puisse appréhender. Avant même de pouvoir songer à manipuler un *input* par l’algorithme, il convient donc d’être capable de l’expliciter. En cela, la pratique du *mapping* intervient une première fois en amont du processus de conception de l’algorithme, et est généralement considérée comme une étape de numérisation. Si cette numérisation peut sembler amputer l’objet à algorithmiser, il s’agit cependant de questionner ce qu’elle lui apporte : en permettant une appréhension algorithmique de cet objet, on gagne la capacité de l’exprimer sur d’autres plans d’existence, de le transformer, de le faire évoluer, de le *mapper*. D’outil de rationalisation l’algorithme devient alors outil de manipulation et de transposition, et offre la capacité d’insuffler une sensibilité nouvelle aux objets algorithmisés.


